{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patatone/Analysis-of-the-COVID-19-impact-on-LTE-Networks/blob/main/Analysis_of_the_COVID_19_impact_on_LTE_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install geopandas\n",
        "%pip install kneed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJzSaICMEkSl",
        "outputId": "f063a3f8-fa56-40b9-fd01-692f245dcd86"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.4)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.21)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (22.1.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2022.6.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kneed in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from kneed) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from kneed) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mES5hp1Gm2dw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import datetime\n",
        "from sklearn.cluster import KMeans\n",
        "from kneed import KneeLocator\n",
        "from google.colab import files"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xGAFRMlm2dz"
      },
      "source": [
        "# Import Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rxWqc0ARm2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d987ad-b340-4f41-f65d-1ed807c17ef6"
      },
      "source": [
        "from google.colab import drive\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Use this Section to import the data files provided in the project folder.\n",
        "\n",
        "# NETWORK KPI\n",
        "# Location: Milan ; Reference month: either January, February or March 2020:\n",
        "\n",
        "## Google drive required lines\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/MRN_data/'\n",
        "\n",
        "## Local path required lines\n",
        "# file_path = ''\n",
        "\n",
        "# KPIs\n",
        "# We select January, February and March\n",
        "all_files = glob.glob(os.path.join(file_path , \"Milano_800*.csv\"))\n",
        "li = []\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "data = pd.concat(li, axis=0, ignore_index=True)\n",
        "\n",
        "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "# Cells Location:\n",
        "locations = pd.read_csv(file_path+'Coordinates_MILANO.csv')\n",
        "\n",
        "# Drop all possible duplicate rows and drop all possible rows with any NaN and NaT values\n",
        "locations = locations.drop_duplicates().dropna()\n",
        "\n",
        "# https://pandas.pydata.org\n",
        "\n",
        "# This section shows some information regarding the dataset\n",
        "print(20*'*')\n",
        "print('Data types:\\n')\n",
        "print(data.dtypes)\n",
        "print(20*'*')  \n",
        "print('Number of data points: ', len(data))\n",
        "print('Number of columns in the dataset: ', len(data.columns))\n",
        "print(20*'*')\n",
        "print(data.isnull().sum(axis=0)) # this command show the number of NON valid data points for each column of the dataset:\n",
        "                                 # a KPI measure for some timestamp can get lost during the storing procedure\n",
        "print(20*'*')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "********************\n",
            "Data types:\n",
            "\n",
            "REGIONE                    object\n",
            "COMUNE                     object\n",
            "Date               datetime64[ns]\n",
            "ECELL_ID                   object\n",
            "DL_BW                     float64\n",
            "RRC_S_SR                  float64\n",
            "RRC_RE_SR                 float64\n",
            "ERAB_S_SR                 float64\n",
            "CS_SR                     float64\n",
            "IntraF_Hout_SR            float64\n",
            "InterF_Hout_SR            float64\n",
            "Hin_SR                    float64\n",
            "DL_VOL                    float64\n",
            "UL_VOL                    float64\n",
            "DL_THR_AVG                float64\n",
            "UL_THR_AVG                float64\n",
            "DL_THR_MAX                float64\n",
            "UL_THR_MAX                float64\n",
            "USERNUM_MAX               float64\n",
            "PRB_DL_Used_Avg           float64\n",
            "PRB_UL_Used_Avg           float64\n",
            "dtype: object\n",
            "********************\n",
            "Number of data points:  841085\n",
            "Number of columns in the dataset:  21\n",
            "********************\n",
            "REGIONE                0\n",
            "COMUNE                 0\n",
            "Date                   0\n",
            "ECELL_ID               0\n",
            "DL_BW                  0\n",
            "RRC_S_SR            2724\n",
            "RRC_RE_SR          43325\n",
            "ERAB_S_SR           2835\n",
            "CS_SR                  0\n",
            "IntraF_Hout_SR     41661\n",
            "InterF_Hout_SR      7127\n",
            "Hin_SR              3996\n",
            "DL_VOL                 0\n",
            "UL_VOL                 0\n",
            "DL_THR_AVG             0\n",
            "UL_THR_AVG             0\n",
            "DL_THR_MAX             0\n",
            "UL_THR_MAX             0\n",
            "USERNUM_MAX            0\n",
            "PRB_DL_Used_Avg        0\n",
            "PRB_UL_Used_Avg        0\n",
            "dtype: int64\n",
            "********************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQhjrQSzm2d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfbab19-b214-4260-a76d-ed65255d663f"
      },
      "source": [
        "# Here you can understand the size of the scenario, \n",
        "# i.e., how many cells you are considering.\n",
        "print('Number of (distinct) cells: ', len(data.drop_duplicates(subset='ECELL_ID')))\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of (distinct) cells:  398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNkEuXeYm2d1"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can split the dataset into tree perdios:\n",
        "# Full lockdown -> from \"9th March 2020\" to \"31th March 2020\"(last data)\n",
        "# Restrictions -> from \"16th February 2020\" to \"9th March 2020\"\n",
        "# Covid free - > from \"1 January 2020\"(first data) to \"16th February 2020\"\n",
        "\n",
        "full_lockdown_end_date = pd.Timestamp(year=2020, month=4, day=1, hour = 0, minute =1)\n",
        "full_lockdown_start_date = pd.Timestamp(year=2020, month=3, day=8, hour = 23, minute =59)\n",
        "\n",
        "restrictions_end_date = pd.Timestamp(year=2020, month=3, day=10, hour = 0, minute =1)\n",
        "restrictions_start_date = pd.Timestamp(year=2020, month=2, day=15, hour = 23, minute =59)\n",
        "\n",
        "covid_free_end_date = pd.Timestamp(year=2020, month=2, day=17, hour = 0, minute =1)\n",
        "covid_free_start_date = pd.Timestamp(year=2019, month=12, day=12, hour = 23, minute =59)\n",
        "\n",
        "\n",
        "full_lockdown = data[data['Date'] < full_lockdown_end_date]\n",
        "full_lockdown = full_lockdown[full_lockdown['Date'] > full_lockdown_start_date]\n",
        "\n",
        "restrictions = data[data['Date'] < restrictions_end_date]\n",
        "restrictions = restrictions[restrictions['Date'] > restrictions_start_date]\n",
        "\n",
        "covid_free = data[data['Date'] < covid_free_end_date]\n",
        "covid_free = covid_free[covid_free['Date'] > covid_free_start_date]\n"
      ],
      "metadata": {
        "id": "TGAvFr4KgedG"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6rVxiqdMm2d2"
      },
      "source": [
        "# Typically, daily and night KPIs traces are analysed differently, as network users \n",
        "# show very different behaviours depending on the two moments. \n",
        "#In this section, the considered weekly data are grouped into Daily (from 6AM to 24 PM) \n",
        "# and Night (from 00 AM to 6 AM) Data\n",
        "\n",
        "# January\n",
        "#week_day = week.set_index('Date').between_time('06:00:00', '23:59:59')\n",
        "#week_night = week.set_index('Date').between_time('00:00:00', '05:59:59')\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_cluster_pattern(dataset):\n",
        "  dt = dataset.copy()\n",
        "  df1 = dt[dt['Clusters'] == 0]\n",
        "\n",
        "  plt.plot(list(range(0,len(df1))), df1['DL_VOL'])\n",
        "  plt.show()\n",
        "\n",
        "  df2 = dt[dt['Clusters'] == 1]\n",
        "\n",
        "  plt.plot(list(range(0,len(df2))), df2['DL_VOL'])\n",
        "  plt.show()\n",
        "\n",
        "  df3 = dt[dt['Clusters'] == 2]\n",
        "\n",
        "  plt.plot(list(range(0,len(df3))), df3['DL_VOL'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "A-tdqg6MNRc-"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLUSTERING PART \n",
        "\n",
        "#filtering by weekdays and daily business hours\n",
        "x = covid_free[covid_free['Date'].dt.hour.between(6, 24)]\n",
        "\n",
        "hours = pd.to_datetime(x['Date']).dt.hour\n",
        "weekdays = x['Date'].dt.weekday\n",
        "x['Hour'] = hours\n",
        "x['Weekday'] = weekdays\n",
        "\n",
        "\n",
        "#creating dataset with relevant data from previous DataFrame\n",
        "x = x[['ECELL_ID', 'DL_VOL', 'Hour', 'Weekday']]\n",
        "#x = x.groupby(['ECELL_ID', 'Hour', 'Weekday']).mean()\n",
        "x = x.reset_index()\n",
        "#splitting between week and weekend days\n",
        "x['Weekday'] = x['Weekday'].apply(lambda x : 0 if x < 5 else (1 if x == 5 else 2))\n",
        "x = x.groupby(['ECELL_ID', 'Hour', 'Weekday']).mean()\n",
        "x = x.reset_index()\n",
        "\n",
        "kmeans_kwargs = {\n",
        "    \"init\": \"k-means++\",\n",
        "    \"n_init\": 10,\n",
        "    \"max_iter\": 300,\n",
        "    \"random_state\": 0,\n",
        "    }\n",
        "\n",
        "# selecting the DL_Volume column as entry data for the k-means clustering algorithm\n",
        "dl_array = x[['DL_VOL', 'Hour', 'Weekday']]\n",
        "sse = []\n",
        "for k in range(1, 11):\n",
        "  # creating a 2 clusters k-means value clustering class and fitting the DataFrame accordingly\n",
        "  kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
        "  identified_clusters = kmeans.fit(dl_array)\n",
        "  sse.append(kmeans.inertia_)\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "plt.plot(range(1, 11), sse)\n",
        "plt.xticks(range(1, 11))\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"SSE\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# Determining the elbow point in the SSE curve\n",
        "kl = KneeLocator(range(1, 11), sse, curve=\"convex\", direction=\"decreasing\")\n",
        "k = kl.elbow\n",
        "print('Perfect \"k\" value for the KMeans algorithm:', k)\n",
        "print()\n",
        "\n",
        "# creating a \"k\" clusters k-means value clustering class and fitting the DataFrame accordingly\n",
        "kmeans = KMeans(n_clusters=k).fit(dl_array)\n",
        "identified_clusters = kmeans.fit_predict(dl_array)\n",
        "data_with_clusters = x.copy()\n",
        "data_with_clusters['Clusters'] = identified_clusters\n",
        "\n",
        "# Scattering the plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "img = ax.scatter(data_with_clusters['Hour'], data_with_clusters['Weekday'], data_with_clusters['DL_VOL'], c = data_with_clusters['Clusters'],\n",
        "            cmap='rainbow')\n",
        "fig.colorbar(img)\n",
        "plt.show()\n",
        "\n",
        "print_cluster_pattern(data_with_clusters)\n",
        "\n",
        "data_with_clusters = data_with_clusters.join(locations.set_index('ECELL_ID'), on='ECELL_ID')\n",
        "data_with_clusters = data_with_clusters[['ENODEB_ID', 'Clusters']]\n",
        "\n",
        "# We cannot use mean(), it's wrong. We have to use mode()\n",
        "#data_with_clusters = data_with_clusters.groupby(['ECELL_ID']).mean().round()\n",
        "\n",
        "# data_with_clusters.to_csv('df.csv')\n",
        "# files.download('df.csv')\n",
        "\n",
        "data_with_clusters = data_with_clusters.groupby('ENODEB_ID', as_index=False)['Clusters'].apply(lambda x: x.mode().iloc[0])\n",
        "#data_with_clusters = data_with_clusters.groupby('ENODEB_ID')['Clusters'].apply(lambda x: x.value_counts().index[0]).reset_index()\n",
        "print(len(data_with_clusters))\n",
        "\n",
        "# Splitting residential cells from non-residential ones\n",
        "support_residential = data_with_clusters[data_with_clusters['Clusters'] == 0]\n",
        "print(len(support_residential))\n",
        "support_promiscuous = data_with_clusters[data_with_clusters['Clusters'] == 1]\n",
        "print(len(support_promiscuous))\n",
        "support_business = data_with_clusters[data_with_clusters['Clusters'] == 2]\n",
        "print(len(support_business))\n",
        "\n",
        "support_residential = support_residential.reset_index()\n",
        "support_business = support_business.reset_index()\n",
        "support_promiscuous = support_promiscuous.reset_index()\n",
        "\n",
        "data_enodebs = data.copy().join(locations.set_index('ECELL_ID'), on='ECELL_ID')\n",
        "# Splitting all the data according to the clusters\n",
        "residential_data = data.loc[data_enodebs['ENODEB_ID'].isin(support_residential['ENODEB_ID'])].reset_index(drop=True)\n",
        "business_data = data.loc[data_enodebs['ENODEB_ID'].isin(support_business['ENODEB_ID'])].reset_index(drop=True)\n",
        "promiscuous_data = data.loc[data_enodebs['ENODEB_ID'].isin(support_promiscuous['ENODEB_ID'])].reset_index(drop=True)\n",
        "\n",
        "# Splitting all the locations according to the clusters\n",
        "residential_locations = locations.loc[locations['ENODEB_ID'].isin(support_residential['ENODEB_ID'])].reset_index(drop=True)\n",
        "business_locations = locations.loc[locations['ENODEB_ID'].isin(support_business['ENODEB_ID'])].reset_index(drop=True)\n",
        "promiscuous_locations = locations.loc[locations['ENODEB_ID'].isin(support_promiscuous['ENODEB_ID'])].reset_index(drop=True)\n",
        "\n",
        "display(residential_locations)\n",
        "display(business_locations)\n",
        "display(promiscuous_locations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2YLBFZ2LcEn",
        "outputId": "98f9ed6b-9fcf-4f0d-8436-e681477eac38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ze8cKYGtKgGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can split the CLUSTERED dataset into tree perdios:\n",
        "# Full lockdown -> from \"9th March 2020\" to \"31th March 2020\"(last data)\n",
        "# Restrictions -> from \"16th February 2020\" to \"9th March 2020\"\n",
        "# Covid free - > from \"1 January 2020\"(first data) to \"16th February 2020\"\n",
        "\n",
        "full_lockdown_residential = residential_data[residential_data['Date'] < full_lockdown_end_date]\n",
        "full_lockdown_residential = full_lockdown_residential[full_lockdown_residential['Date'] > full_lockdown_start_date]\n",
        "\n",
        "full_lockdown_business = business_data[business_data['Date'] < full_lockdown_end_date]\n",
        "full_lockdown_business = full_lockdown_business[full_lockdown_business['Date'] > full_lockdown_start_date]\n",
        "\n",
        "restrictions_residential = residential_data[residential_data['Date'] < restrictions_end_date]\n",
        "restrictions_residential = restrictions_residential[restrictions_residential['Date'] > restrictions_start_date]\n",
        "\n",
        "restrictions_business = business_data[business_data['Date'] < restrictions_end_date]\n",
        "restrictions_business = restrictions_business[restrictions_business['Date'] > restrictions_start_date]\n",
        "\n",
        "covid_free_residential = residential_data[residential_data['Date'] < covid_free_end_date]\n",
        "covid_free_residential = covid_free_residential[covid_free_residential['Date'] > covid_free_start_date]\n",
        "\n",
        "covid_free_business = business_data[business_data['Date'] < covid_free_end_date]\n",
        "covid_free_business = covid_free_business[covid_free_business['Date'] > covid_free_start_date]\n",
        "\n",
        "periods_lables = ['Covid Free','Restrictions','Full Lockdown']\n",
        "periods_data = [covid_free, restrictions, full_lockdown]\n",
        "for i in range(0, 3):\n",
        "  print('Number of', periods_lables[i], 'data points:', len(periods_data[i]))\n"
      ],
      "metadata": {
        "id": "ENuyhqqpdEW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMCPQkp0Ak_w"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This section plots the Traffic Downloaded from the ALL cells in a month\n",
        "\n",
        "def periods_trace_plot_daily(ref_KPI, operation, ylabel):\n",
        "  # Create a copy of the original dataset\n",
        "  data_temp = data.copy()\n",
        "\n",
        "  # Set Daily granularity instead of Hourly granularity\n",
        "  data_temp['Date'] = pd.to_datetime(data_temp['Date']).dt.date\n",
        "\n",
        "  # Used to identify days with less measurments\n",
        "  # pd.set_option('display.max_rows', None)\n",
        "  # display(data_temp['Date'].value_counts())\n",
        "\n",
        "  # We drop the data about 31-03-2020 because we are computing daily stats and in this date we have only one measurment for the whole day\n",
        "  ref = data_temp.set_index('Date').sort_values('Date').drop(datetime.date(year=2020,month=3,day=31)).loc[:, [ref_KPI]]\n",
        "\n",
        "  print('Original dataset size:', len(ref))\n",
        "  print('Cleaned dataset size:', len(ref.dropna()))\n",
        "\n",
        "  # Sum all the \"ref_KPI\" values with same \"Date\"\n",
        "  ref = ref.groupby(level=0).sum()\n",
        "\n",
        "  # open new figure\n",
        "  fig, ax = plt.subplots(figsize=(15,8))\n",
        "\n",
        "  # plot data\n",
        "  ax.plot(list(range(0,len(ref))), ref[ref_KPI], linestyle='--', lw=2, color='b', alpha=.8) \n",
        "\n",
        "  # Set plotting options\n",
        "  plt.xticks(color='black')\n",
        "  plt.yticks(color='black')\n",
        "  plt.grid(1)\n",
        "  ticks_label = ref.index\n",
        "  ticks = np.linspace(0, len(ref)-1, 35, dtype=int)\n",
        "  plt.xticks(ticks = ticks, labels = ticks_label[ticks], fontsize = 14)\n",
        "  plt.setp( ax.xaxis.get_majorticklabels(), rotation=-45, ha=\"left\", rotation_mode=\"anchor\") \n",
        "  plt.xlabel('Date', color='black', fontsize=14)\n",
        "  plt.ylabel(ylabel, color='black', fontsize=14) # unit of measure depends on the considered KPI\n",
        "  plt.title('Median Hourly Trace of '+ref_KPI+' - ALL CELLS', fontsize=14)\n",
        "\n",
        "  # Draw a red line when there is a period change\n",
        "  plt.axvline(ticks_label.get_loc(datetime.date(year=2020,month=2,day=16)) ,color = 'r',label = 'Restrictions')\n",
        "  plt.axvline(ticks_label.get_loc(datetime.date(year=2020,month=3,day=9)) ,color = 'r',label = 'Full Lockdown')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "periods_trace_plot_daily('DL_VOL', 0, 'Bits')\n",
        "print()\n",
        "periods_trace_plot_daily('UL_VOL', 0, 'Bits')\n",
        "print()"
      ],
      "metadata": {
        "id": "a9D_4-idTybJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell rappresentation with Geopandas\n",
        "geo_data = geopandas.GeoDataFrame(locations, geometry=geopandas.points_from_xy(locations.LONG_X, locations.LAT_Y))\n",
        "\n",
        "# Plot the map\n",
        "milan = geopandas.read_file(file_path+'ds379_municipi_label.geojson')\n",
        "ax = milan.plot(color='lightblue', edgecolor='black', figsize=[12,15])\n",
        "\n",
        "# Plot the cells\n",
        "geo_data.plot(ax=ax, color='red')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-fFwFAn6DvmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell differentiation with Geopandas\n",
        "geo_data_residential = geopandas.GeoDataFrame(residential_locations, geometry=geopandas.points_from_xy(residential_locations.LONG_X, residential_locations.LAT_Y))\n",
        "geo_data_business = geopandas.GeoDataFrame(business_locations, geometry=geopandas.points_from_xy(business_locations.LONG_X, business_locations.LAT_Y))\n",
        "geo_data_promiscuous  = geopandas.GeoDataFrame(promiscuous_locations, geometry=geopandas.points_from_xy(promiscuous_locations.LONG_X, promiscuous_locations.LAT_Y))\n",
        "\n",
        "# Plot the map\n",
        "milan = geopandas.read_file(file_path+'ds379_municipi_label.geojson')\n",
        "ax = milan.plot(color='lightblue', edgecolor='black', figsize=[12,15])\n",
        "\n",
        "# Plot the cells\n",
        "geo_data_residential.plot(ax=ax, color='green')\n",
        "geo_data_business.plot(ax=ax, color='blue')\n",
        "geo_data_promiscuous.plot(ax=ax, color='yellow')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1YHyFHrOLkq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This section makes a box plot of the daily statiscs regarding the number of connected \n",
        "# users to the cell taken as example. For each day, the following statistics are extracted from the considered\n",
        "# KPI:\n",
        "# - Median Value\n",
        "# - 25th and 75th Quantiles\n",
        "# - Max and Min values\n",
        "\n",
        "# For reference about how to read a box plot go here: \n",
        "# https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51\n",
        "\n",
        "\n",
        "def data_dataset_daily(dataset, ref_KPI):\n",
        "  # Set Daily granularity instead of Hourly granularity\n",
        "  dataset['Date'] = pd.to_datetime(dataset['Date']).dt.date\n",
        "  # Set new dataset index to \"Date\" and keep only the \"ref_KPI\" column\n",
        "  return dataset.set_index('Date').sort_values('Date').loc[:, [ref_KPI]]\n",
        "\n",
        "\n",
        "# If operation == 0 do the sum of the ref_KPI of the day\n",
        "# If operation == 1 do the average of the ref_KPI of the day\n",
        "def dataset_operation(dataset, operation):\n",
        "  if operation == 0:\n",
        "    dataset = dataset.groupby(level=0).sum()\n",
        "  else:\n",
        "    dataset = dataset.groupby(level=0).mean()\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def statistical_comparison(periods_lables, median_values, average_values, sd_values, id_1, id_2, ref_KPI):\n",
        "  print('>>>------', periods_lables[id_1], ref_KPI, 'Variation ------<<<')\n",
        "  print(\"Median: difference between [\", periods_lables[id_1] ,\"] and [\",periods_lables[id_2] ,\"]: {0:.2f}%\".format(((median_values[id_2] - median_values[id_1]) / abs(median_values[id_1])) * 100))\n",
        "  print(\"Average: difference between [\", periods_lables[id_1] ,\"] and [\",periods_lables[id_2] ,\"]: {0:.2f}%\".format(((average_values[id_2] - average_values[id_1]) / abs(average_values[id_1])) * 100))\n",
        "  print(\"Std. deviation: difference between [\", periods_lables[id_1] ,\"] and [\",periods_lables[id_2] ,\"]: {0:.2f}%\".format(((sd_values[id_2] - sd_values[id_1]) / abs(sd_values[id_1])) * 100))\n",
        "\n",
        "\n",
        "def periods_box_plot_daily(periods, periods_lables, ref_KPI, operation, ylabel):\n",
        "\n",
        "  periods_copy = []\n",
        "  periods_data_list = []\n",
        "  N_periods = len(periods)\n",
        "\n",
        "  for i in range(N_periods):\n",
        "    periods_copy.append(periods[i].copy())\n",
        "    periods_copy[i] = data_dataset_daily(periods_copy[i], ref_KPI)\n",
        "    periods_copy[i] = periods_copy[i].loc[:, [ref_KPI]].drop(datetime.date(year=2020,month=3,day=31), errors='ignore')\n",
        "    # Remove null values\n",
        "    periods_copy[i] = periods_copy[i].dropna()\n",
        "    periods_copy[i] = dataset_operation(periods_copy[i], ref_KPI)\n",
        "    # periods_copy have only one KPI but we need \"[ref_KPI]\" to use the \"tolist()\" function\n",
        "    periods_data_list.append(periods_copy[i][ref_KPI].tolist())\n",
        "\n",
        "  # open new figure\n",
        "  fig, ax = plt.subplots(figsize=(15,8))\n",
        "\n",
        "  bplots = []\n",
        "  for i in range(N_periods):\n",
        "    bplots.append(ax.boxplot(periods_data_list[i], positions = [i], patch_artist=True))\n",
        "\n",
        "  for bplot in bplots:\n",
        "    for patch in bplot['boxes']:\n",
        "      patch.set_facecolor('lightblue')\n",
        "\n",
        "  # Set plotting options\n",
        "  plt.xticks(color='black')\n",
        "  plt.yticks(color='black')\n",
        "  plt.grid(1)\n",
        "  plt.xticks(ticks = list(range(N_periods)), labels = periods_lables, fontsize = 14)\n",
        "  plt.setp( ax.xaxis.get_majorticklabels(), ha=\"center\") \n",
        "  plt.ylabel(ylabel, color='black', fontsize=14)\n",
        "  if N_periods > 3:\n",
        "    plt.setp( ax.xaxis.get_majorticklabels(), rotation=-45, ha=\"left\", rotation_mode=\"anchor\") \n",
        "\n",
        "  plt.title('Box Plot of Median '+ref_KPI+' - ALL CELLs', fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "  print()\n",
        "  \n",
        "  median_values = []\n",
        "  average_values = []\n",
        "  sd_values = []\n",
        "\n",
        "  # Print statistical informations:\n",
        "  for i in range(N_periods):\n",
        "    print('---------', periods_lables[i], ref_KPI,'---------')\n",
        "    median_values.append(np.median(periods_data_list[i]))\n",
        "    print('Median value:', \"{0:.2f}\".format(median_values[i]))\n",
        "    average_values.append(np.mean(periods_data_list[i]))\n",
        "    print('Average value:', \"{0:.2f}\".format( average_values[i]))\n",
        "    sd_values.append(np.std(periods_data_list[i]))\n",
        "    print('Standard deviation:', \"{0:.2f}\".format(sd_values[i]))\n",
        "\n",
        "  if N_periods > 3:\n",
        "    # Statistical comparison between residential and business in the same period\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 0, 1, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 2, 3, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 4, 5, ref_KPI)\n",
        "\n",
        "    # Statistical comparison between residential periods\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 0, 2, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 0, 4, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 2, 4, ref_KPI)\n",
        "\n",
        "    # Statistical comparison between business periods\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 1, 3, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 1, 5, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 3, 5, ref_KPI)\n",
        "  else:\n",
        "    # Statistical comparison between periods\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 0, 1, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 0, 2, ref_KPI)\n",
        "    statistical_comparison(periods_lables, median_values, average_values, sd_values, 1, 2, ref_KPI)\n"
      ],
      "metadata": {
        "id": "XWmUTsSM_JWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_stats(periods, periods_lables):\n",
        "  periods_box_plot_daily(periods, periods_lables, 'DL_VOL', 0, 'Bits')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'UL_VOL', 0, 'Bits')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'DL_THR_MAX', 1, 'Bits')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'UL_THR_MAX', 1, 'Bits')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'DL_THR_AVG', 1, 'Bits')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'UL_THR_AVG', 1, 'Bits')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'ERAB_S_SR', 1, 'Success Rate')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'CS_SR', 1, 'Calls')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'RRC_S_SR', 1, 'Success Rate')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'RRC_RE_SR', 1, 'Success Rate')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'IntraF_Hout_SR', 1, 'Success Rate')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'InterF_Hout_SR', 1, 'Success Rate')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'Hin_SR', 1, 'Success Rate')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'PRB_DL_Used_Avg', 1, 'Bits')\n",
        "  print()\n",
        "  periods_box_plot_daily(periods, periods_lables, 'PRB_UL_Used_Avg', 1, 'Bits')\n",
        "  print()"
      ],
      "metadata": {
        "id": "dwbsqcSNSV3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "periods = [covid_free, restrictions, full_lockdown]\n",
        "plot_stats(periods, periods_lables)"
      ],
      "metadata": {
        "id": "P_VIvz14RsyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "periods = [covid_free_residential, covid_free_business, restrictions_residential, restrictions_business, full_lockdown_residential, full_lockdown_business]\n",
        "periods_lables = ['Covid Free Residential', 'Covid Free Business', 'Restrictions Residential', 'Restrictions Business', 'Full Lockdown Residential', 'Full Lockdown Business']\n",
        "plot_stats(periods, periods_lables)"
      ],
      "metadata": {
        "id": "Wuh1jvRKQtqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}